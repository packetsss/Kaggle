{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>...</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.00000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.456643</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.219286</td>\n      <td>0.117095</td>\n      <td>0.059024</td>\n      <td>0.02019</td>\n      <td>0.017238</td>\n      <td>0.002857</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.887730</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6.312890</td>\n      <td>4.633819</td>\n      <td>3.274488</td>\n      <td>1.75987</td>\n      <td>1.894498</td>\n      <td>0.414264</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>254.000000</td>\n      <td>254.000000</td>\n      <td>253.000000</td>\n      <td>253.00000</td>\n      <td>254.000000</td>\n      <td>62.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 785 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(39900, 28, 28, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "X, y = df.drop(\"label\", axis=1), df.label\n",
    "X.shape, y.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=5)\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "X_train = np.array([X_train]).reshape(-1, 28, 28, 1)\n",
    "X_test = np.array([X_test]).reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.Sequential([\n",
    "    # cnn layer\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    keras.layers.Conv2D(filters=8, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # keras.layers.Conv2D(filters=4, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    # keras.layers.BatchNormalization(),\n",
    "    # keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "\n",
    "    # dense layer\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "1247/1247 [==============================] - 4s 3ms/step - loss: 0.2034 - accuracy: 0.9384\n",
      "Epoch 2/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0657 - accuracy: 0.9789\n",
      "Epoch 3/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0480 - accuracy: 0.9848\n",
      "Epoch 4/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0378 - accuracy: 0.9879\n",
      "Epoch 5/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0317 - accuracy: 0.9889\n",
      "Epoch 6/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0255 - accuracy: 0.9914\n",
      "Epoch 7/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0201 - accuracy: 0.9930\n",
      "Epoch 8/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0191 - accuracy: 0.9932\n",
      "Epoch 9/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0156 - accuracy: 0.9948\n",
      "Epoch 10/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0141 - accuracy: 0.9952\n",
      "Epoch 11/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0120 - accuracy: 0.9958\n",
      "Epoch 12/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0111 - accuracy: 0.9961\n",
      "Epoch 13/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0100 - accuracy: 0.9965\n",
      "Epoch 14/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0090 - accuracy: 0.9968\n",
      "Epoch 15/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0072 - accuracy: 0.9972\n",
      "Epoch 16/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0089 - accuracy: 0.9969\n",
      "Epoch 17/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0071 - accuracy: 0.9975\n",
      "Epoch 18/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0079 - accuracy: 0.9972\n",
      "Epoch 19/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "Epoch 20/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "Epoch 21/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0062 - accuracy: 0.9977\n",
      "Epoch 22/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0051 - accuracy: 0.9981\n",
      "Epoch 23/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0073 - accuracy: 0.9975\n",
      "Epoch 24/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0048 - accuracy: 0.9982\n",
      "Epoch 25/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 26/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 27/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0054 - accuracy: 0.9981\n",
      "Epoch 28/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 29/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 30/30\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0034 - accuracy: 0.9985\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bcadc77a00>"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       223\n           1       0.99      1.00      1.00       234\n           2       0.96      0.98      0.97       200\n           3       1.00      0.97      0.99       221\n           4       1.00      0.98      0.99       189\n           5       0.99      0.99      0.99       180\n           6       1.00      0.99      1.00       203\n           7       0.99      0.97      0.98       239\n           8       0.96      0.99      0.98       195\n           9       0.97      1.00      0.98       216\n\n    accuracy                           0.99      2100\n   macro avg       0.99      0.99      0.99      2100\nweighted avg       0.99      0.99      0.99      2100\n\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "y_pred = [np.argmax(x) for x in y_pred]\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_new = keras.Sequential([\n",
    "    # cnn layer\n",
    "    keras.layers.Conv2D(filters=8, kernel_size=(3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    keras.layers.Conv2D(filters=4, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # keras.layers.Conv2D(filters=4, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    # keras.layers.BatchNormalization(),\n",
    "    # keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "\n",
    "    # dense layer\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn_new.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.3302 - accuracy: 0.8986\n",
      "Epoch 2/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0978 - accuracy: 0.9691\n",
      "Epoch 3/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0710 - accuracy: 0.9770\n",
      "Epoch 4/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0561 - accuracy: 0.9819\n",
      "Epoch 5/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0482 - accuracy: 0.9840\n",
      "Epoch 6/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0401 - accuracy: 0.9873\n",
      "Epoch 7/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0371 - accuracy: 0.9874\n",
      "Epoch 8/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0310 - accuracy: 0.9900\n",
      "Epoch 9/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0283 - accuracy: 0.9910\n",
      "Epoch 10/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0242 - accuracy: 0.9918\n",
      "Epoch 11/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0235 - accuracy: 0.9922\n",
      "Epoch 12/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0205 - accuracy: 0.9933\n",
      "Epoch 13/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0183 - accuracy: 0.9942\n",
      "Epoch 14/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0178 - accuracy: 0.9939\n",
      "Epoch 15/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0159 - accuracy: 0.9946\n",
      "Epoch 16/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0147 - accuracy: 0.9948\n",
      "Epoch 17/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0134 - accuracy: 0.9955\n",
      "Epoch 18/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0126 - accuracy: 0.9954\n",
      "Epoch 19/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0108 - accuracy: 0.9962\n",
      "Epoch 20/20\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.0112 - accuracy: 0.9959\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bc876a67c0>"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "cnn_new.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       1.00      0.99      0.99       223\n           1       1.00      1.00      1.00       234\n           2       0.99      0.95      0.97       200\n           3       0.97      0.99      0.98       221\n           4       0.99      0.99      0.99       189\n           5       0.97      0.98      0.98       180\n           6       0.99      0.99      0.99       203\n           7       0.98      0.99      0.98       239\n           8       0.99      0.96      0.97       195\n           9       0.98      1.00      0.99       216\n\n    accuracy                           0.98      2100\n   macro avg       0.98      0.98      0.98      2100\nweighted avg       0.98      0.98      0.98      2100\n\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn_new.predict(X_test)\n",
    "y_pred = [np.argmax(x) for x in y_pred]\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = np.array([df_test]).reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_pred_final = cnn.predict(X_test_final)\n",
    "y_pred_final = [np.argmax(x) for x in y_pred_final]\n",
    "\n",
    "\n",
    "df_result = pd.DataFrame({\"ImageId\": range(1, 28001), \"Label\": y_pred_final})\n",
    "df_result.to_csv(\"result_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2bcadd00130>"
      ]
     },
     "metadata": {},
     "execution_count": 40
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 288x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"257.778125pt\" version=\"1.1\" viewBox=\"0 0 257.325 257.778125\" width=\"257.325pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-06-28T17:30:19.515447</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 257.778125 \r\nL 257.325 257.778125 \r\nL 257.325 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 247.078125 \r\nL 250.125 247.078125 \r\nL 250.125 23.878125 \r\nL 26.925 23.878125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p027032da7c)\">\r\n    <image height=\"224\" id=\"image70e2e572f5\" transform=\"scale(1 -1)translate(0 -224)\" width=\"224\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-23.078125\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mb13cf46c40\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.910714\" xlink:href=\"#mb13cf46c40\" y=\"247.078125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_2\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 -3.5 \r\n\" id=\"m8aad2a4fee\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.910714\" xlink:href=\"#m8aad2a4fee\" y=\"23.878125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(27.729464 14.798438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2034 4250 \r\nQ 1547 4250 1301 3770 \r\nQ 1056 3291 1056 2328 \r\nQ 1056 1369 1301 889 \r\nQ 1547 409 2034 409 \r\nQ 2525 409 2770 889 \r\nQ 3016 1369 3016 2328 \r\nQ 3016 3291 2770 3770 \r\nQ 2525 4250 2034 4250 \r\nz\r\nM 2034 4750 \r\nQ 2819 4750 3233 4129 \r\nQ 3647 3509 3647 2328 \r\nQ 3647 1150 3233 529 \r\nQ 2819 -91 2034 -91 \r\nQ 1250 -91 836 529 \r\nQ 422 1150 422 2328 \r\nQ 422 3509 836 4129 \r\nQ 1250 4750 2034 4750 \r\nz\r\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"70.767857\" xlink:href=\"#mb13cf46c40\" y=\"247.078125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"70.767857\" xlink:href=\"#m8aad2a4fee\" y=\"23.878125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(67.586607 14.798438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 691 4666 \r\nL 3169 4666 \r\nL 3169 4134 \r\nL 1269 4134 \r\nL 1269 2991 \r\nQ 1406 3038 1543 3061 \r\nQ 1681 3084 1819 3084 \r\nQ 2600 3084 3056 2656 \r\nQ 3513 2228 3513 1497 \r\nQ 3513 744 3044 326 \r\nQ 2575 -91 1722 -91 \r\nQ 1428 -91 1123 -41 \r\nQ 819 9 494 109 \r\nL 494 744 \r\nQ 775 591 1075 516 \r\nQ 1375 441 1709 441 \r\nQ 2250 441 2565 725 \r\nQ 2881 1009 2881 1497 \r\nQ 2881 1984 2565 2268 \r\nQ 2250 2553 1709 2553 \r\nQ 1456 2553 1204 2497 \r\nQ 953 2441 691 2322 \r\nL 691 4666 \r\nz\r\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"110.625\" xlink:href=\"#mb13cf46c40\" y=\"247.078125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"110.625\" xlink:href=\"#m8aad2a4fee\" y=\"23.878125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(104.2625 14.798438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 794 531 \r\nL 1825 531 \r\nL 1825 4091 \r\nL 703 3866 \r\nL 703 4441 \r\nL 1819 4666 \r\nL 2450 4666 \r\nL 2450 531 \r\nL 3481 531 \r\nL 3481 0 \r\nL 794 0 \r\nL 794 531 \r\nz\r\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"150.482143\" xlink:href=\"#mb13cf46c40\" y=\"247.078125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"150.482143\" xlink:href=\"#m8aad2a4fee\" y=\"23.878125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(144.119643 14.798438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"190.339286\" xlink:href=\"#mb13cf46c40\" y=\"247.078125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"190.339286\" xlink:href=\"#m8aad2a4fee\" y=\"23.878125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(183.976786 14.798438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 1228 531 \r\nL 3431 531 \r\nL 3431 0 \r\nL 469 0 \r\nL 469 531 \r\nQ 828 903 1448 1529 \r\nQ 2069 2156 2228 2338 \r\nQ 2531 2678 2651 2914 \r\nQ 2772 3150 2772 3378 \r\nQ 2772 3750 2511 3984 \r\nQ 2250 4219 1831 4219 \r\nQ 1534 4219 1204 4116 \r\nQ 875 4013 500 3803 \r\nL 500 4441 \r\nQ 881 4594 1212 4672 \r\nQ 1544 4750 1819 4750 \r\nQ 2544 4750 2975 4387 \r\nQ 3406 4025 3406 3419 \r\nQ 3406 3131 3298 2873 \r\nQ 3191 2616 2906 2266 \r\nQ 2828 2175 2409 1742 \r\nQ 1991 1309 1228 531 \r\nz\r\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.196429\" xlink:href=\"#mb13cf46c40\" y=\"247.078125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.196429\" xlink:href=\"#m8aad2a4fee\" y=\"23.878125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(223.833929 14.798438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_13\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"md189539a5d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#md189539a5d\" y=\"27.863839\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 31.663058)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#md189539a5d\" y=\"67.720982\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(13.5625 71.520201)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#md189539a5d\" y=\"107.578125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 111.377344)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#md189539a5d\" y=\"147.435268\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 151.234487)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_17\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#md189539a5d\" y=\"187.292411\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 191.091629)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#md189539a5d\" y=\"227.149554\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 230.948772)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 247.078125 \r\nL 26.925 23.878125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 250.125 247.078125 \r\nL 250.125 23.878125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 247.078125 \r\nL 250.125 247.078125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 23.878125 \r\nL 250.125 23.878125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p027032da7c\">\r\n   <rect height=\"223.2\" width=\"223.2\" x=\"26.925\" y=\"23.878125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.matshow(X_test[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}