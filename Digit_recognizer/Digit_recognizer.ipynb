{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>...</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.00000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.456643</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.219286</td>\n      <td>0.117095</td>\n      <td>0.059024</td>\n      <td>0.02019</td>\n      <td>0.017238</td>\n      <td>0.002857</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.887730</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6.312890</td>\n      <td>4.633819</td>\n      <td>3.274488</td>\n      <td>1.75987</td>\n      <td>1.894498</td>\n      <td>0.414264</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>254.000000</td>\n      <td>254.000000</td>\n      <td>253.000000</td>\n      <td>253.00000</td>\n      <td>254.000000</td>\n      <td>62.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 785 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(39900, 28, 28, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "X, y = df.drop(\"label\", axis=1), df.label\n",
    "X.shape, y.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=5)\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "X_train = np.array([X_train]).reshape(-1, 28, 28, 1)\n",
    "X_test = np.array([X_test]).reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "X_train = X_train.reshape(len(X_train), 28 * 28)\n",
    "X_test = X_test.reshape(len(X_test), 28 * 28)\n",
    "X_train = np.array([X_train]).reshape(-1, 28, 28, 1)\n",
    "X_test = np.array([X_test]).reshape(-1, 28, 28, 1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.Sequential([\n",
    "    # cnn layer\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    keras.layers.Conv2D(filters=8, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # keras.layers.Conv2D(filters=4, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    # keras.layers.BatchNormalization(),\n",
    "    # keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "\n",
    "    # dense layer\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1643 - accuracy: 0.9501\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0552 - accuracy: 0.9830\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0407 - accuracy: 0.9873\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0333 - accuracy: 0.9893\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0276 - accuracy: 0.9908\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0222 - accuracy: 0.9927\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0194 - accuracy: 0.9935\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0158 - accuracy: 0.9948\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0151 - accuracy: 0.9951\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0119 - accuracy: 0.9957\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0118 - accuracy: 0.9960\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0107 - accuracy: 0.9962\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0093 - accuracy: 0.9969\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0081 - accuracy: 0.9975\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0086 - accuracy: 0.9971\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0082 - accuracy: 0.9973\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0074 - accuracy: 0.9974\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0058 - accuracy: 0.9980\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0065 - accuracy: 0.9980\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0057 - accuracy: 0.9978\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0055 - accuracy: 0.9980\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0053 - accuracy: 0.9981\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0042 - accuracy: 0.9984\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0043 - accuracy: 0.9984\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bcadc61a00>"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.99       980\n           1       0.99      1.00      0.99      1135\n           2       0.99      0.98      0.99      1032\n           3       0.99      0.99      0.99      1010\n           4       0.99      0.98      0.99       982\n           5       0.99      0.98      0.99       892\n           6       0.99      0.98      0.99       958\n           7       0.98      0.99      0.99      1028\n           8       0.99      0.98      0.99       974\n           9       0.98      0.98      0.98      1009\n\n    accuracy                           0.99     10000\n   macro avg       0.99      0.99      0.99     10000\nweighted avg       0.99      0.99      0.99     10000\n\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "y_pred = [np.argmax(x) for x in y_pred]\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = np.array([df_test]).reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_pred_final = cnn.predict(X_test_final)\n",
    "y_pred_final = [np.argmax(x) for x in y_pred_final]\n",
    "\n",
    "\n",
    "df_result = pd.DataFrame({\"ImageId\": range(1, 28001), \"Label\": y_pred_final})\n",
    "df_result.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "source": [
    "## Great Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "cnn_new = keras.Sequential([\n",
    "    # preprocessing\n",
    "    preprocessing.RandomContrast(0.2),\n",
    "    preprocessing.RandomTranslation(height_factor=0.1,width_factor=0.1),\n",
    "\n",
    "    # cnn\n",
    "    layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "    layers.BatchNormalization(axis=1),\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "    layers.BatchNormalization(axis=1),\n",
    "    layers.Conv2D(filters=128, kernel_size=5, activation='relu'),\n",
    "    layers.BatchNormalization(axis=1),\n",
    "    layers.Conv2D(filters=128, kernel_size=5, activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.BatchNormalization(axis=1),\n",
    "\n",
    "    # output\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=1024,activation='relu'),\n",
    "    layers.Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_new.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0223 - accuracy: 0.9932\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0198 - accuracy: 0.9941\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0190 - accuracy: 0.9943\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0170 - accuracy: 0.9949\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0169 - accuracy: 0.9947\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0149 - accuracy: 0.9956\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0147 - accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0151 - accuracy: 0.9953\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0136 - accuracy: 0.9962\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0128 - accuracy: 0.9962\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bc9ce041f0>"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "cnn_new.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       1.00      0.99      1.00       980\n           1       0.99      1.00      1.00      1135\n           2       0.99      1.00      1.00      1032\n           3       0.99      1.00      1.00      1010\n           4       0.99      0.99      0.99       982\n           5       1.00      0.99      0.99       892\n           6       1.00      0.99      0.99       958\n           7       1.00      0.99      1.00      1028\n           8       0.99      1.00      1.00       974\n           9       0.99      1.00      0.99      1009\n\n    accuracy                           0.99     10000\n   macro avg       1.00      0.99      0.99     10000\nweighted avg       1.00      0.99      0.99     10000\n\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn_new.predict(X_test)\n",
    "y_pred = [np.argmax(x) for x in y_pred]\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = np.array([df_test]).reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_pred_final = cnn_new.predict(X_test_final)\n",
    "y_pred_final = [np.argmax(x) for x in y_pred_final]\n",
    "\n",
    "\n",
    "df_result = pd.DataFrame({\"ImageId\": range(1, 28001), \"Label\": y_pred_final})\n",
    "df_result.to_csv(\"result_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2bc9ce04220>"
      ]
     },
     "metadata": {},
     "execution_count": 84
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 288x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"257.778125pt\" version=\"1.1\" viewBox=\"0 0 257.325 257.778125\" width=\"257.325pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-06-28T18:08:23.242086</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 257.778125 \r\nL 257.325 257.778125 \r\nL 257.325 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 247.078125 \r\nL 250.125 247.078125 \r\nL 250.125 23.878125 \r\nL 26.925 23.878125 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p1b0699405f)\">\r\n    <image height=\"224\" id=\"imagec105312efe\" transform=\"scale(1 -1)translate(0 -224)\" width=\"224\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-23.078125\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mb66499b4dd\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.910714\" xlink:href=\"#mb66499b4dd\" y=\"247.078125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_2\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 -3.5 \r\n\" id=\"me1cd6143b7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.910714\" xlink:href=\"#me1cd6143b7\" y=\"23.878125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(27.729464 14.798438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2034 4250 \r\nQ 1547 4250 1301 3770 \r\nQ 1056 3291 1056 2328 \r\nQ 1056 1369 1301 889 \r\nQ 1547 409 2034 409 \r\nQ 2525 409 2770 889 \r\nQ 3016 1369 3016 2328 \r\nQ 3016 3291 2770 3770 \r\nQ 2525 4250 2034 4250 \r\nz\r\nM 2034 4750 \r\nQ 2819 4750 3233 4129 \r\nQ 3647 3509 3647 2328 \r\nQ 3647 1150 3233 529 \r\nQ 2819 -91 2034 -91 \r\nQ 1250 -91 836 529 \r\nQ 422 1150 422 2328 \r\nQ 422 3509 836 4129 \r\nQ 1250 4750 2034 4750 \r\nz\r\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"70.767857\" xlink:href=\"#mb66499b4dd\" y=\"247.078125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"70.767857\" xlink:href=\"#me1cd6143b7\" y=\"23.878125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(67.586607 14.798438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 691 4666 \r\nL 3169 4666 \r\nL 3169 4134 \r\nL 1269 4134 \r\nL 1269 2991 \r\nQ 1406 3038 1543 3061 \r\nQ 1681 3084 1819 3084 \r\nQ 2600 3084 3056 2656 \r\nQ 3513 2228 3513 1497 \r\nQ 3513 744 3044 326 \r\nQ 2575 -91 1722 -91 \r\nQ 1428 -91 1123 -41 \r\nQ 819 9 494 109 \r\nL 494 744 \r\nQ 775 591 1075 516 \r\nQ 1375 441 1709 441 \r\nQ 2250 441 2565 725 \r\nQ 2881 1009 2881 1497 \r\nQ 2881 1984 2565 2268 \r\nQ 2250 2553 1709 2553 \r\nQ 1456 2553 1204 2497 \r\nQ 953 2441 691 2322 \r\nL 691 4666 \r\nz\r\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"110.625\" xlink:href=\"#mb66499b4dd\" y=\"247.078125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"110.625\" xlink:href=\"#me1cd6143b7\" y=\"23.878125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(104.2625 14.798438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 794 531 \r\nL 1825 531 \r\nL 1825 4091 \r\nL 703 3866 \r\nL 703 4441 \r\nL 1819 4666 \r\nL 2450 4666 \r\nL 2450 531 \r\nL 3481 531 \r\nL 3481 0 \r\nL 794 0 \r\nL 794 531 \r\nz\r\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"150.482143\" xlink:href=\"#mb66499b4dd\" y=\"247.078125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"150.482143\" xlink:href=\"#me1cd6143b7\" y=\"23.878125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(144.119643 14.798438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"190.339286\" xlink:href=\"#mb66499b4dd\" y=\"247.078125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"190.339286\" xlink:href=\"#me1cd6143b7\" y=\"23.878125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(183.976786 14.798438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 1228 531 \r\nL 3431 531 \r\nL 3431 0 \r\nL 469 0 \r\nL 469 531 \r\nQ 828 903 1448 1529 \r\nQ 2069 2156 2228 2338 \r\nQ 2531 2678 2651 2914 \r\nQ 2772 3150 2772 3378 \r\nQ 2772 3750 2511 3984 \r\nQ 2250 4219 1831 4219 \r\nQ 1534 4219 1204 4116 \r\nQ 875 4013 500 3803 \r\nL 500 4441 \r\nQ 881 4594 1212 4672 \r\nQ 1544 4750 1819 4750 \r\nQ 2544 4750 2975 4387 \r\nQ 3406 4025 3406 3419 \r\nQ 3406 3131 3298 2873 \r\nQ 3191 2616 2906 2266 \r\nQ 2828 2175 2409 1742 \r\nQ 1991 1309 1228 531 \r\nz\r\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.196429\" xlink:href=\"#mb66499b4dd\" y=\"247.078125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.196429\" xlink:href=\"#me1cd6143b7\" y=\"23.878125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(223.833929 14.798438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_13\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m0f3629622d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0f3629622d\" y=\"27.863839\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 31.663058)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0f3629622d\" y=\"67.720982\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(13.5625 71.520201)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0f3629622d\" y=\"107.578125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 111.377344)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0f3629622d\" y=\"147.435268\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 151.234487)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_17\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0f3629622d\" y=\"187.292411\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 191.091629)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0f3629622d\" y=\"227.149554\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 230.948772)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 247.078125 \r\nL 26.925 23.878125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 250.125 247.078125 \r\nL 250.125 23.878125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 247.078125 \r\nL 250.125 247.078125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 23.878125 \r\nL 250.125 23.878125 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p1b0699405f\">\r\n   <rect height=\"223.2\" width=\"223.2\" x=\"26.925\" y=\"23.878125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.matshow(X_test[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}